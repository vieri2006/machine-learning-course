{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Hand Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnqHG0xAeH7uzVo7CTM91N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vieri2006/machine-learning-course/blob/master/Machine_Learning_Hand_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIIyMNQCsXk3",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to my assignment\n",
        "## Vieri Wijaya - Dicoding\n",
        "\n",
        "### Fitur yang tidak diajarkan:\n",
        "1. Menggunakan dropout untuk mengurangi overfitting\n",
        "2. Menggunakan activation function bernama `LeakyReLu` yang konon katanya lebih efisien\n",
        "3. Melakukan train-test split karena jika tidak, ada dataset train yang masuk ke dataset validasi sehingga mengurangi keabsahan validasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2J66lLHs-yO",
        "colab_type": "text"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdiNUMtJdOEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "591ce8a6-382d-445e-d023-d66f2134ed99"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#to split dataset\n",
        "import shutil\n",
        "import os\n",
        "import math\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "#to plot and upload results\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzfst5q3tCc1",
        "colab_type": "text"
      },
      "source": [
        "## Download Datasets dan prepare datasets dirs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlhyPdIOx9f6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4ba536c6-f061-4abd-a153-f7685860de3a"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-08 19:39:16--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/zip]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  7.98MB/s    in 43s     \n",
            "\n",
            "2020-05-08 19:40:01 (7.08 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0nEBYGjdRoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "srcdir = '/tmp/data_awal/'\n",
        "workdir = '/tmp/dataset/'\n",
        "\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(srcdir)\n",
        "zip_ref.close()\n",
        "\n",
        "srcdir += 'rockpaperscissors/'\n",
        "shutil.rmtree(srcdir+'/rps-cv-images')\n",
        "\n",
        "#Jika merun ulang, biar tidak ada duplikat\n",
        "try:\n",
        "  shutil.rmtree(workdir)\n",
        "  os.mkdir(workdir)\n",
        "except:\n",
        "  os.mkdir(workdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFgsxGcf3bH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f781b4e8-65b3-41cd-cd7e-69a854074784"
      },
      "source": [
        "os.chdir(srcdir)\n",
        "category_list = list(filter(lambda x: os.path.isdir(x), os.listdir()))\n",
        "\n",
        "for category in category_list:\n",
        "  print(category)\n",
        "\n",
        "data_set_dirs= ['train', 'valid']\n",
        "for dsdirs in data_set_dirs:\n",
        "  path = workdir + '/'+ dsdirs\n",
        "  os.mkdir(path)\n",
        "\n",
        "train_prop = 0.85\n",
        "valid_prop = 1 - train_prop\n",
        "\n",
        "for cat in category_list: \n",
        "  src_path = srcdir + '/' + cat\n",
        "  dest_dir1 = workdir + '/train/' + cat\n",
        "  dest_dir2 = workdir + '/valid/' + cat\n",
        "  dest_dirs_list = [dest_dir1, dest_dir2]\n",
        "\n",
        "  os.chdir(src_path)\n",
        "  files_ = [f for f in os.listdir() if os.path.isfile(f)]\n",
        "  train_count = math.ceil(train_prop * len(files_))\n",
        "  train_data_list = files_[0 : train_count]\n",
        "  valid_data_list = files_[train_count :] \n",
        "\n",
        "  for dirs in dest_dirs_list:\n",
        "    os.mkdir(dirs)\n",
        "\n",
        "  for train_data in train_data_list:\n",
        "    train_path = src_path + '/' + train_data\n",
        "    shutil.copy(train_path, dest_dir1)\n",
        "\n",
        "  for valid_data in valid_data_list:\n",
        "    valid_path = src_path + '/' + valid_data\n",
        "    shutil.copy(valid_path, dest_dir2)\n",
        "\n",
        "train_dir = os.path.join(workdir, 'train')\n",
        "valid_dir = os.path.join(workdir, 'valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paper\n",
            "scissors\n",
            "rock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpHlNH2Nydh5",
        "colab_type": "text"
      },
      "source": [
        "## Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-C77mK1wKx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range = 0.15,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLYoSs6jxYWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8944a9d2-99b0-4e61-9a5b-e6d53184bd37"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(150, 150), \n",
        "        batch_size=32,\n",
        "        #color_mode='grayscale',\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        valid_dir, \n",
        "        #color_mode='grayscale',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32, \n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1862 images belonging to 3 classes.\n",
            "Found 326 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJGeuWCgyziV",
        "colab_type": "text"
      },
      "source": [
        "## CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NcWBUzCy_HJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "0b389873-b64c-4d78-9249-01ce0273ac7d"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3)),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3)),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3)),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3)),\n",
        "    tf.keras.layers.LeakyReLU(0.2),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(150, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 148, 148, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 70, 70, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 70, 70, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 33, 33, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 33, 33, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 256)       295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               1881750   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 453       \n",
            "=================================================================\n",
            "Total params: 2,307,547\n",
            "Trainable params: 2,307,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOJA03l4zIaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnmm1mjOy3qU",
        "colab_type": "text"
      },
      "source": [
        "## CNN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C-crfjRzTtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fda32cf7-de98-49f1-e56b-f08c9d7a7a92"
      },
      "source": [
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25, \n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=10, \n",
        "      )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 71s 3s/step - loss: 0.9047 - accuracy: 0.5475 - val_loss: 0.5787 - val_accuracy: 0.8156\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 67s 3s/step - loss: 0.4806 - accuracy: 0.8175 - val_loss: 0.2820 - val_accuracy: 0.9031\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 65s 3s/step - loss: 0.3591 - accuracy: 0.8734 - val_loss: 0.2999 - val_accuracy: 0.8969\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 67s 3s/step - loss: 0.2898 - accuracy: 0.8900 - val_loss: 0.1780 - val_accuracy: 0.9375\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 65s 3s/step - loss: 0.2574 - accuracy: 0.9005 - val_loss: 0.2480 - val_accuracy: 0.9094\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 67s 3s/step - loss: 0.1790 - accuracy: 0.9438 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 67s 3s/step - loss: 0.1577 - accuracy: 0.9438 - val_loss: 0.1125 - val_accuracy: 0.9594\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 66s 3s/step - loss: 0.1198 - accuracy: 0.9625 - val_loss: 0.0733 - val_accuracy: 0.9812\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 67s 3s/step - loss: 0.1423 - accuracy: 0.9550 - val_loss: 0.1343 - val_accuracy: 0.9750\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 69s 3s/step - loss: 0.1416 - accuracy: 0.9509 - val_loss: 0.1147 - val_accuracy: 0.9563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4580f8a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZM_3xOky7-I",
        "colab_type": "text"
      },
      "source": [
        "## Production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RONRys2H_dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150), #color_mode='grayscale'\n",
        "                       )\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)[0]\n",
        "  \n",
        "  print(fn)\n",
        "  \n",
        "  if classes[0]:\n",
        "    print('Paper')\n",
        "  elif classes[1]:\n",
        "    print('Rock')\n",
        "  else:\n",
        "    print('Scissors')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}